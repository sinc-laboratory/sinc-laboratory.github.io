---
title: Crowdsourced Audio Annotation and Quality Evaluation
order: 3
image_path: /assets/images/caqe.png
image_description: "A bunch of ears in a cloud."
selected_publications:
- /publications/2022-04-01-mendez2022eliciting
- /publications/2019-04-01-cartwright2019crowdsourcing
- /publications/2018-04-01-cartwright2018crowdsourcedpairwise
- /publications/2017-11-01-cartwright2017seeing
- /publications/2016-04-01-cartwright2016fast
---
To address the needs of modern, data hungry machine learning algorithms, audio researchers often turn to crowdsourcing with the aim of hastening and scaling their efforts for audio annotation and audio quality evaluation. We research best practices for performing crowdsourced audio annotation and quality evaluation with the aim of increasing annotation quality, throughput, and user engagement. 